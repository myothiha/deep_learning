{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network (Basic)\n",
    "\n",
    "- Creat a model.\n",
    "- Choose a appropriate loss function.\n",
    "- Create a dataset.\n",
    "- Define a optimizer.\n",
    "- Run a training Loop.\n",
    "    - calculate loss (forward pass).\n",
    "    - Calculate gradients.\n",
    "    - Update the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>job_title</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>20.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender  education  job_title  experience    salary\n",
       "0  32.0       1          0        159         5.0   90000.0\n",
       "1  28.0       0          1         17         3.0   65000.0\n",
       "2  45.0       1          2        130        15.0  150000.0\n",
       "3  36.0       0          0        101         7.0   60000.0\n",
       "4  52.0       1          1         22        20.0  200000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/salary_data_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['age', 'experience']\n",
    "target_cols = ['salary']\n",
    "inputs = df[feature_cols].values\n",
    "targets = df[target_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = torch.tensor(inputs).float()\n",
    "input_tensor = torch.tensor(inputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_tensor = torch.tensor(targets).float()\n",
    "target_tensor = torch.tensor(targets, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([373, 2]), torch.Size([373, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape, target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7fb1fe2db1f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(input_tensor, target_tensor)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset.\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size =  len(dataset) - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7fb21c1767c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_input, batch_target in dataloader:\n",
    "#     print(batch_input.shape, batch_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=input_tensor.shape[-1], out_features=10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=10, out_features=5),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5), # Dropout layer: regularization. p=0.5 => set 50% of output neurons to zero.\n",
    "    nn.Linear(in_features=5, out_features=5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=5, out_features=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(batch_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Weight decay regularizaiton\n",
    "# weight decay will add penalty term to the loss function to make the weight params small.\n",
    "# higher value => less likely to overfit.\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.005, weight_decay=1e-4) \n",
    "\n",
    "# Without Weight Decay regularization\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val_batch_input, val_batch_target in val_loader:\n",
    "#     break;\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     yhat = model(val_batch_input)\n",
    "#     print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 5671784755.20 | Val Loss: 4527600896.00\n",
      "Epoch 1: Train Loss: 4914308659.20 | Val Loss: 3137552768.00\n",
      "Epoch 2: Train Loss: 4483439180.80 | Val Loss: 3494546304.00\n",
      "Epoch 3: Train Loss: 4044477696.00 | Val Loss: 3469208960.00\n",
      "Epoch 4: Train Loss: 3831949644.80 | Val Loss: 1823806496.00\n",
      "Epoch 5: Train Loss: 3565278822.40 | Val Loss: 2945678592.00\n",
      "Epoch 6: Train Loss: 3384737292.80 | Val Loss: 2677851392.00\n",
      "Epoch 7: Train Loss: 3064547008.00 | Val Loss: 5064065408.00\n",
      "Epoch 8: Train Loss: 2936999654.40 | Val Loss: 2767123072.00\n",
      "Epoch 9: Train Loss: 2728264012.80 | Val Loss: 2498087808.00\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for batch_input, batch_target in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(batch_input)\n",
    "\n",
    "        loss = criterion(y_hat, batch_target)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()        \n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    validation_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch_input, val_batch_target in val_loader:\n",
    "            y_hat = model(val_batch_input)\n",
    "            # print(y_hat)\n",
    "\n",
    "            loss = criterion(y_hat, val_batch_target)\n",
    "            validation_loss += loss.item()  \n",
    "\n",
    "    avg_val_loss = validation_loss/len(val_loader)\n",
    "    print(f\"Epoch {epoch}: Train Loss: {total_loss/len(train_loader):.2f} | Val Loss: {avg_val_loss:.2f}\")\n",
    "        \n",
    "    if epoch % 100 == 0 and epoch != 0:\n",
    "        # print(f\"Epoch {epoch}: Train Loss: {total_loss/len(train_loader):.2f} | Val Loss: {avg_val_loss:.2f}\")\n",
    "        print(f\"Epoch {epoch}: Train Loss: {total_loss/len(train_loader):.2f}\")\n",
    "        # print(model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_Datacamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
